{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of RAG Pipeline\n",
        "\n",
        "The provided Python code sets up a Retrieval-Augmented Generation (RAG) system. It begins by importing necessary libraries: `Groq` for interacting with the Groq API, `faiss` for efficient similarity search, `pandas` for data handling, `sentence_transformers` for generating embeddings, and `json` for handling JSON responses. The key components initialized are:\n",
        "\n",
        "*   `client_key_config`: An instance of the Groq client, configured with an API key, to communicate with Groq's language models.\n",
        "*   `fine_tune_embedding`: A `SentenceTransformer` model loaded from a local path (`/content/drive/MyDrive/Colab Notebooks/fine_tuned_qoute-retriever`). This model is responsible for converting text into numerical vector representations (embeddings).\n",
        "*   `fine_tune_vector_index`: A FAISS index loaded from `/content/drive/MyDrive/Colab Notebooks/vector_databse/quotes_vector_db.faiss`. This index stores the embeddings of the quotes and allows for fast similarity searches.\n",
        "*   `fine_tune_metadata`: A pandas DataFrame loaded from `/content/drive/MyDrive/Colab Notebooks/vector_databse/quotes_metadata.pkl`. This DataFrame contains the original quote texts and potentially other metadata, mapped by their index in the FAISS vector store.\n",
        "\n",
        "*   The `query_response` function is the core of the RAG pipeline. It takes a user query, processes it through the RAG system, and returns the LLM's response along with the retrieved quotes.\n",
        "\n",
        "#### RAG Pipeline Implementation\n",
        "The `query_response` function implements a RAG pipeline in the following steps:\n",
        "\n",
        "1.  **Embedding the Query**: The input `query` is first encoded into a numerical vector using the `fine_tune_embedding` model (`query_vector = fine_tune_embedding.encode([query]).astype('float32')`).\n",
        "2.  **Retrieval**: This query vector is then used to search the `fine_tune_vector_index` (FAISS) to find the top 3 most semantically similar quotes. The `search` method returns distances and indices of these top matches.\n",
        "3.  **Context Construction**: The indices obtained from FAISS are used to retrieve the full quote texts from the `fine_tune_metadata` DataFrame. These retrieved quotes are then formatted into a `context_text` string.\n",
        "4.  **Augmented Generation**: A `prompt` is constructed that includes both the user's original `query` and the `context_text` (retrieved quotes). This prompt instructs the LLM to act as a 'wise philosopher' and use the quotes to answer the question, or use them as inspiration.\n",
        "5.  **LLM Call**: The constructed prompt is sent to the specified LLM (Groq's Llama 3.3 70b versatile) via the `client_key_config.chat.completions.create` method. The LLM is specifically instructed to respond in JSON format.\n",
        "6.  **Response**: The function returns the JSON response from the LLM and the list of retrieved quotes.\n",
        "\n",
        "#### Fine-tuned Embedding Model and FAISS Vector Index\n",
        "*   **Fine-tuned Embedding Model**: The `SentenceTransformer` model (`fine_tune_embedding`) is crucial for converting textual information (queries and quotes) into high-dimensional numerical vectors (embeddings). The fact that it's 'fine-tuned' suggests it has been adapted to the specific domain of quotes, potentially improving the relevance of retrieval compared to a generic model.\n",
        "*   **FAISS Vector Index**: FAISS (Facebook AI Similarity Search) is a library for efficient similarity search and clustering of dense vectors. The `fine_tune_vector_index` allows the system to quickly find the most similar quote embeddings to a given query embedding, even from a very large collection of quotes. This efficiency is critical for real-time RAG applications.\n",
        "\n",
        "#### Specific LLM: Groq's Llama 3.3 70b Versatile\n",
        "The system leverages `Groq's Llama 3.3 70b versatile` model as the Large Language Model (LLM). Groq provides fast inference for large models, making it suitable for interactive applications. The LLM's role is to synthesize an answer based on the user's query and the provided context (retrieved quotes). It acts as the 'philosopher' in this setup, generating a coherent and relevant response in JSON format, as specified in the prompt and `response_format` parameter.\n",
        "\n",
        "#### Analysis of Results from `query_response(\"Show me quotes about courage by women author\")`\n",
        "The example query \"Show me quotes about courage by women author\" yields an interesting output, highlighting both the strengths and limitations of the RAG setup in this specific instance.\n",
        "\n",
        "**LLM Response (JSON):**\n",
        "```json\n",
        "{\n",
        "  \"quotes_about_courage\": [\n",
        "       {\n",
        "           \"quote\": \"I, with a deeper instinct, choose a man who compels my strength, who makes enormous demands on me, who does not doubt my courage or my toughness, who does not believe me naive or innocent, who has the courage to treat me like a woman.\",\n",
        "           \"author\": \"Anaïs Nin\"\n",
        "       }\n",
        "   ],\n",
        "   \"inspired_by\": \"The provided quotes, although mostly from male authors, inspired the search for a quote from a female author that captures the essence of courage.\",\n",
        "   \"note\": \"Unfortunately, only one quote from the retrieved collection is from a female author, but it showcases the idea that courage is not just about personal strength, but also about being treated with respect and having the courage to make demands on others.\"\n",
        "}\n",
        "```\n",
        "\n",
        "**Retrieved Quotes:**\n",
        "```\n",
        "['\"i wanted you to see what real courage is, instead of getting the idea that courage is a man with a gun in his hand. it's when you know you're licked before you begin, but you begin anyway and see it through no matter what.- atticus finch\"',\n",
        "'\"courage isn't having the strength to go on - it is going on when you don't have strength.\"',\n",
        "'\"i, with a deeper instinct, choose a man who compels my strength, who makes enormous demands on me, who does not doubt my courage or my toughness, who does not believe me naa ve or innocent, who has the courage to treat me like a woman.\"']\n",
        "```\n",
        "\n",
        "**Effectiveness of RAG Pipeline:**\n",
        "*   The RAG pipeline successfully retrieved quotes related to 'courage'. However, out of the top 3 retrieved quotes, only one is from a woman author (Anaïs Nin), which partially addresses the 'women author' constraint.\n",
        "*   The LLM correctly identified and extracted the Anaïs Nin quote as directly relevant to the 'women author' criterion, placing it under `quotes_about_courage`. This indicates that the LLM is capable of filtering and categorizing information based on prompt instructions, even when the retrieval is not perfectly aligned with all constraints.\n",
        "\n",
        "**Relevance of Retrieved Quotes:**\n",
        "*   All three retrieved quotes are highly relevant to the concept of 'courage'. The first two are well-known quotes about courage (one attributed to Atticus Finch, the other a general saying). The third, from Anaïs Nin, directly relates to a woman's perspective on courage.\n",
        "*   The embedding model seems effective at capturing the semantic meaning of 'courage' in its retrieval.\n",
        "\n",
        "**LLM's Context Utilization and Handling of Constraints:**\n",
        "*   The LLM explicitly acknowledges the limitation in the retrieved context regarding the 'women author' constraint in the `inspired_by` and `note` fields. It states that most of the retrieved quotes were from male authors but that the context still 'inspired' its response.\n",
        "*   The LLM made an effort to fulfill the user's request by isolating the only relevant quote from a female author it could find in the provided context.\n",
        "*   The `note` field demonstrates the LLM's ability to provide meta-commentary on the quality or completeness of the provided context, which is a valuable feature for transparency in RAG systems.\n",
        "*   This analysis shows that while the retrieval component might not always perfectly match all nuanced aspects of a query (like specific author demographics), the LLM can intelligently process the available context and communicate the discrepancies. This also suggests that the initial fine-tuning of the embedding model might not have heavily emphasized author metadata, or the dataset itself had a bias towards male authors for 'courage' quotes, which is an area for potential improvement in the RAG system by either refining the embedding model's training data or expanding the quote database with more diverse authors.\n"
      ],
      "metadata": {
        "id": "1SvpW-QeA1db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ragas datasets langchain-community langchain-core sentence-transformers groq  langchain-groq faiss-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8zAXRONDRVi",
        "outputId": "a6cde2d8-9714-48d6-a2e3-3160618813f4",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ragas\n",
            "  Downloading ragas-0.4.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.6)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-1.2.7-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from ragas) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from ragas) (0.12.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ragas) (2.12.3)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ragas) (1.6.0)\n",
            "Collecting appdirs (from ragas)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting diskcache>=5.6.3 (from ragas)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from ragas) (0.21.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from ragas) (13.9.4)\n",
            "Requirement already satisfied: openai>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ragas) (2.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from ragas) (4.67.1)\n",
            "Collecting instructor (from ragas)\n",
            "  Downloading instructor-1.14.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pillow>=10.4.0 in /usr/local/lib/python3.12/dist-packages (from ragas) (11.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from ragas) (3.6.1)\n",
            "Collecting scikit-network (from ragas)\n",
            "  Downloading scikit_network-0.33.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (from ragas) (1.2.3)\n",
            "Collecting langchain_openai (from ragas)\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.2)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.13.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Collecting groq\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->ragas) (0.12.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->ragas) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->ragas) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from instructor->ragas) (0.17.0)\n",
            "Collecting jiter<1,>=0.10.0 (from openai>=1.0.0->ragas)\n",
            "  Downloading jiter-0.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting pre-commit>=4.3.0 (from instructor->ragas)\n",
            "  Downloading pre_commit-4.5.1-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting ty>=0.0.1a23 (from instructor->ragas)\n",
            "  Downloading ty-0.0.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->ragas) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->ragas) (2.19.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer->ragas) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->ragas) (1.5.4)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain->ragas) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain->ragas) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain->ragas) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain->ragas) (0.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
            "  Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
            "  Downloading identify-2.6.16-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit>=4.3.0->instructor->ragas)\n",
            "  Downloading nodeenv-1.10.0-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
            "  Downloading virtualenv-20.36.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain->ragas) (1.12.1)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas) (4.5.1)\n",
            "Downloading ragas-0.4.3-py3-none-any.whl (466 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.5/466.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.4.2-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.3/512.3 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.2.7-py3-none-any.whl (490 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.2/490.2 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-1.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading instructor-1.14.3-py3-none-any.whl (174 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.8/174.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_network-0.33.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.8/358.8 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.5.1-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ty-0.0.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Downloading identify-2.6.16-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading nodeenv-1.10.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading virtualenv-20.36.1-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: distlib, appdirs, virtualenv, ty, requests, pyarrow, nodeenv, mypy-extensions, marshmallow, jiter, identify, faiss-cpu, diskcache, cfgv, typing-inspect, scikit-network, pre-commit, groq, dataclasses-json, langchain-core, instructor, datasets, langchain-text-splitters, langchain_openai, langchain-groq, langchain-classic, langchain-community, ragas\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.12.0\n",
            "    Uninstalling jiter-0.12.0:\n",
            "      Successfully uninstalled jiter-0.12.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.6\n",
            "    Uninstalling langchain-core-1.2.6:\n",
            "      Successfully uninstalled langchain-core-1.2.6\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 cfgv-3.5.0 dataclasses-json-0.6.7 datasets-4.4.2 diskcache-5.6.3 distlib-0.4.0 faiss-cpu-1.13.2 groq-0.37.1 identify-2.6.16 instructor-1.14.3 jiter-0.11.1 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-core-1.2.7 langchain-groq-1.1.1 langchain-text-splitters-1.1.0 langchain_openai-1.1.7 marshmallow-3.26.2 mypy-extensions-1.1.0 nodeenv-1.10.0 pre-commit-4.5.1 pyarrow-22.0.0 ragas-0.4.3 requests-2.32.5 scikit-network-0.33.5 ty-0.0.11 typing-inspect-0.9.0 virtualenv-20.36.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nmmeUH5jCzWe"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "import faiss\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import json\n",
        "\n",
        "client_key_config = Groq(api_key=\"Enter your groq api key\")\n",
        "fine_tune_embedding = SentenceTransformer('/content/drive/MyDrive/Colab Notebooks/fine_tuned_qoute-retriever')\n",
        "fine_tune_vector_index = faiss.read_index(\"/content/drive/MyDrive/Colab Notebooks/vector_databse/quotes_vector_db.faiss\")\n",
        "fine_tune_metadata = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/vector_databse/quotes_metadata.pkl\")\n",
        "\n",
        "def query_response(query):\n",
        "    query_vector = fine_tune_embedding.encode([query]).astype('float32')\n",
        "    distances, indices = fine_tune_vector_index.search(query_vector, k=3)\n",
        "\n",
        "    retrieved_quotes = [fine_tune_metadata.iloc[idx]['quote_clean'] for idx in indices[0]]\n",
        "    context_text = \"\\n\".join([f\"- {q}\" for q in retrieved_quotes])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a wise philosopher. Use the following quotes to answer the user's question.\n",
        "    If the quotes aren't enough, use them as inspiration for your answer.\n",
        "\n",
        "    Retrieved Quotes:\n",
        "    {context_text}\n",
        "\n",
        "    User Question: {query}\n",
        "\n",
        "    Respond in JSON format with your answer.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client_key_config.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a wise philosopher who responds in JSON format.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        response_format={\"type\": \"json_object\"}\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content, retrieved_quotes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_response(\"Show me quotes about courage by women author\")"
      ],
      "metadata": {
        "id": "3Sy00D9EDPFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f7115f-1042-4b50-9051-d71fb8b14388"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('{\\n  \"quotes_about_courage\": [\\n       {\\n           \"quote\": \"I, with a deeper instinct, choose a man who compels my strength, who makes enormous demands on me, who does not doubt my courage or my toughness, who does not believe me naive or innocent, who has the courage to treat me like a woman.\",\\n           \"author\": \"Anaïs Nin\"\\n       }\\n   ],\\n   \"inspired_by\": \"The provided quotes, although mostly from male authors, inspired the search for a quote from a female author that captures the essence of courage.\",\\n   \"note\": \"Unfortunately, only one quote from the retrieved collection is from a female author, but it showcases the idea that courage is not just about personal strength, but also about being treated with respect and having the courage to make demands on others.\"\\n}',\n",
              " ['\"i wanted you to see what real courage is, instead of getting the idea that courage is a man with a gun in his hand. it\\'s when you know you\\'re licked before you begin, but you begin anyway and see it through no matter what.- atticus finch\"',\n",
              "  '\"courage isn\\'t having the strength to go on - it is going on when you don\\'t have strength.\"',\n",
              "  '\"i, with a deeper instinct, choose a man who compels my strength, who makes enormous demands on me, who does not doubt my courage or my toughness, who does not believe me naa ve or innocent, who has the courage to treat me like a woman.\"'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cbcf993"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The RAG system utilizes a fine-tuned `SentenceTransformer` model for embedding queries and quotes, and a FAISS vector index for efficient similarity search.\n",
        "*   Groq's Llama 3.3 70b versatile model serves as the Large Language Model (LLM) for generating augmented responses.\n",
        "*   For the example query \"Show me quotes about courage by women author,\" the RAG pipeline retrieved quotes highly relevant to 'courage'. However, only one out of the top three retrieved quotes was from a female author, indicating a potential imbalance in the retrieval results concerning specific demographic constraints.\n",
        "*   The LLM successfully identified and extracted the single relevant female author quote from the retrieved context. It also intelligently acknowledged the limitation regarding the 'women author' constraint in its response (in the `inspired_by` and `note` fields), demonstrating its ability to process context critically and provide meta-commentary on retrieval quality.\n",
        "*   The initial attempt to generate the explanation cell encountered a `SyntaxError` due to unescaped backslashes in the markdown string, specifically within the \"Retrieved Quotes\" section, which was subsequently corrected for successful execution.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   To improve the retrieval accuracy for queries with specific author demographic constraints, consider refining the embedding model's training data to include more diverse author metadata or expanding the quote database with a broader representation of authors.\n",
        "*   Leverage the LLM's demonstrated ability to provide meta-commentary on retrieval quality as a feature for enhancing transparency and user understanding in RAG applications, especially when retrieval is not perfectly aligned with all query constraints.\n"
      ]
    }
  ]
}